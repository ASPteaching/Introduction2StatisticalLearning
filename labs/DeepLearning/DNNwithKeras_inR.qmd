---
title:  "Deep Neural Networks with \n Keras in R"
author: "A. Sanchez, F. Reverter and E. Vegas"
format:
  revealjs: 
    incremental: false  
    transition: slide
    background-transition: fade
    transition-speed: slow
    scrollable: true
    menu:
      side: left
      width: half
      numbers: true
    slide-number: c/t
    show-slide-number: all
    progress: true
    css: "../css4CU.css"
    theme: sky
knit:
  quarto:
    chunk_options:
      echo: true
      cache: false
      prompt: false
      tidy: true
      comment: NA
      message: false
      warning: false
    knit_options:
      width: 75
# bibliography: "StatisticalLearning.bib"
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
ggplot2::theme_set(ggplot2::theme_minimal())
workingdir <- paste(here::here(), "labs", sep="/")
setwd(workingdir)
```

# Deep learning with R
##  *Hello world* of deep learning (1)

```{r dataInput, eval=TRUE, echo=TRUE}
# load packages
library(keras)
# input layer: use MNIST images
mnist <- dataset_mnist()
x_train <- mnist$train$x; y_train <- mnist$train$y
x_test <- mnist$test$x; y_test <- mnist$test$y
```


##  *Hello world* of deep learning (2)

```{r preProcess, eval=TRUE, echo=TRUE}
# reshape and rescale
x_train <- array_reshape(x_train, c(nrow(x_train), 784))
x_test <- array_reshape(x_test, c(nrow(x_test), 784))
x_train <- x_train / 255; x_test <- x_test / 255
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)

```

##  *Hello world* of deep learning (3)

```{r defineModel, eval=TRUE, echo=TRUE}
# defining the model and layers
model <- keras_model_sequential()
model %>%
  layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%
  layer_dropout(rate = 0.4) %>%
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dense(units = 10, activation = 'softmax')

```


##  *Hello world* of deep learning (4)

```{r compileModel, eval=TRUE, echo=TRUE}

# compile (define loss and optimizer)
model %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = optimizer_rmsprop(),
  metrics = c('accuracy')
)

```

## *Hello world* of deep learning (5)

```{r fitModel, eval=FALSE, echo=TRUE}
# train (fit)
model %>% fit(
x_train, y_train,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
```

## *Hello world* of deep learning (6)

```{r evaluateModel, eval=FALSE, echo=TRUE}
model %>% evaluate(x_test, y_test)
predictions <- model %>% predict(x_test)
```

# Hyperparameter tuning

## Tuning hyperparameters of DNN

- Tuning the parameters of a DNN requires 
  - Evaluating distinct combinations at multiple points and 
  - Comparing the quality of the fitted models at each combination.

- This can be manually hand-crafted but some tools such as [Tensorboard](https://www.tensorflow.org/tensorboard) or the `tfruns`package facilitate it.


## The `tfruns` package

- Use the [`tfruns`](https://tensorflow.rstudio.com/tools/tfruns/overview/) package to:

  - Track the hyperparameters, metrics, output, and source code of every training run.
  -  Compare hyperparameters and metrics across runs to find the best performing model.
  -  Automatically generate reports to visualize individual training runs or comparisons between runs.

## A `tfruns` example

- Consider the Keras "Hello World" example,
- To test different sizes for `layer1` and `layer2`:
  - Use the `flags` function to set/change values for hyperparameters to be tuned, here  layer sizes.
  - Modify these values iteratively from outside the run (e.g. the script) that uses each value.
  - Compare the results of having trained the model with the distinct sets of values.
- Implemented in `MNIST_tfruns.r`  and `MNIST_flags.r`

## Example: Setting the flags

In `MNIST_flags.r`:

- Set the flags:

```{r eval=FALSE, echo=TRUE}
# set hyperparameter flags
FLAGS <- flags(
  flag_numeric("hl1", 256),
  flag_numeric("hl2", 128)
)
```

- Use the flags:
  
```{r eval=FALSE, echo=TRUE}
model %>%
layer_dense(units = FLAGS$hl1, activation = 'relu',
            input_shape = c(784)) %>%
layer_dense(units = FLAGS$hl2, activation = 'relu') %>%
layer_dense(units = 10, activation = 'softmax')
```

## Example: changing flag values

In `MNIST_tfruns.r`:

- Can use a loop to iterate along distinct flag values:

```{r eval=FALSE, echo=TRUE}
library(tfruns)

for (hl1 in c(200, 300))
  for (hl2 in c(50, 150))
    training_run('MNIST_flags.r', 
                 flags = c(hl1 = hl1))
```

## Comparing distinct runs:

- The metrics and output of each run are automatically captured within a (unique) `runs` directory 
  
- Some functions to view the results are:
  - `latest run()` shows the results of the last run.
  - `view run("runs/2023-05-15T10-19-47Z")` shows the
results of a given run.

- Some `tfruns` functions available from  Rstudio Addins menu.

## Example: Access comparison results

```{r echo=TRUE, eval=FALSE}
# Show last completed run
latest_run()
# Show all runs
ls_runs()
# Show all runs with improved presentation
View(ls_runs())
# show selected items from all runs
ls_runs(metric_val_accuracy > 0.94, 
        order = metric_val_accuracy)
# compare_runs() visual comparison of two training runs. 
compare_runs() # Default is compre two last runs

```


# References and Resources

## References and Resources{.smaller}

### Workshops

- [Deep learning with R *Summer course*](https://bios691-deep-learning-r.netlify.app/)
- [Deep learning with keras and Tensorflow in R (Rstudio conf. 2020)](https://github.com/rstudio-conf-2020/dl-keras-tf)

### Books

- [Deep learning with R, 2nd edition. F. Chollet](https://livebook.manning.com/book/deep-learning-with-r-second-edition)

### Documents

- [7 Best Deep Learning Frameworks To Watch Out For in 2022](https://www.geeksforgeeks.org/7-best-deep-learning-frameworks/)


